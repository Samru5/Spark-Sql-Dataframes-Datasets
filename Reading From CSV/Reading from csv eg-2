
scala>  val df = spark.read.format("csv").option("header", "true").load("C:/Users/sashetye/demo/sample.csv")
df: org.apache.spark.sql.DataFrame = [auctionid: string, bid: string ... 5 more fields]

scala> df.printSchema
root
 |-- auctionid: string (nullable = true)
 |-- bid: string (nullable = true)
 |-- bidtime: string (nullable = true)
 |-- bidder: string (nullable = true)
 |-- bidderrate: string (nullable = true)
 |-- openbid: string (nullable = true)
 |-- price: string (nullable = true)


scala> df.show
+----------+----+-----------+-----------+----------+-------+-----+
| auctionid| bid|    bidtime|     bidder|bidderrate|openbid|price|
+----------+----+-----------+-----------+----------+-------+-----+
|1638843936| 500|0.478368056|  kona-java|       181|    500| 1625|
|1638843936| 800|0.826388889|     doc213|        60|    500| 1625|
|1638843936| 600|3.761122685|       zmxu|         7|    500| 1625|
|1638843936|1500|5.226377315|carloss8055|         5|    500| 1625|
|1638843936|1600|   6.570625|    jdrinaz|         6|    500| 1625|
+----------+----+-----------+-----------+----------+-------+-----+


scala> df.select("auctionid").distinct.count
res41: Long = 1

scala> df.groupBy("bidder").count.show
+-----------+-----+
|     bidder|count|
+-----------+-----+
|       zmxu|    1|
|carloss8055|    1|
|  kona-java|    1|
|     doc213|    1|
|    jdrinaz|    1|
+-----------+-----+


scala> df.registerTempTable("auctions")
warning: there was one deprecation warning; re-run with -deprecation for details

scala> val sql = spark.sql("SELECT count(*) AS count FROM auctions")
sql: org.apache.spark.sql.DataFrame = [count: bigint]


scala> sql.show
+-----+
|count|
+-----+
|    5|
+-----+


scala>  val count = sql.collect()(0).getLong(0)
count: Long = 5


scala> df.filter($"bidder".like("d%")).show
+----------+-----+---------+------+----------+-------+------+
| auctionid|  bid|  bidtime|bidder|bidderrate|openbid| price|
+----------+-----+---------+------+----------+-------+------+
|1638843936|800.0|0.8263889|doc213|        60|  500.0|1625.0|
+----------+-----+---------+------+----------+-------+------+



---------------------------------------------------------------------------------
or


scala> val lines = sc.textFile("C:/Users/sashetye/demo/sample.csv")
lines: org.apache.spark.rdd.RDD[String] = C:/Users/sashetye/demo/sample.csv MapPartitionsRDD[78] at textFile at <console>:30

scala>  val header = lines.first
header: String = auctionid,bid,bidtime,bidder,bidderrate,openbid,price

scala> lines.count
res32: Long = 6

scala> case class Auction(auctionid: String, bid: Float, bidtime: Float, bidder: String, bidderrate: Int, openbid: Float, price: Float)
defined class Auction

scala>  val noheader = lines.filter(_ != header)
noheader: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[79] at filter at <console>:33

scala> val auctions = noheader.map(_.split(",")).map(r => Auction(r(0), r(1).toFloat, r(2).toFloat, r(3), r(4).toInt, r(5).toFloat, r(6).toFloat))
auctions: org.apache.spark.rdd.RDD[Auction] = MapPartitionsRDD[81] at map at <console>:33

scala> val df = auctions.toDF
df: org.apache.spark.sql.DataFrame = [auctionid: string, bid: float ... 5 more fields]

scala> df.printSchema
root
 |-- auctionid: string (nullable = true)
 |-- bid: float (nullable = false)
 |-- bidtime: float (nullable = false)
 |-- bidder: string (nullable = true)
 |-- bidderrate: integer (nullable = false)
 |-- openbid: float (nullable = false)
 |-- price: float (nullable = false)


scala> df.show
+----------+------+----------+-----------+----------+-------+------+
| auctionid|   bid|   bidtime|     bidder|bidderrate|openbid| price|
+----------+------+----------+-----------+----------+-------+------+
|1638843936| 500.0|0.47836804|  kona-java|       181|  500.0|1625.0|
|1638843936| 800.0| 0.8263889|     doc213|        60|  500.0|1625.0|
|1638843936| 600.0| 3.7611227|       zmxu|         7|  500.0|1625.0|
|1638843936|1500.0| 5.2263775|carloss8055|         5|  500.0|1625.0|
|1638843936|1600.0|  6.570625|    jdrinaz|         6|  500.0|1625.0|
+----------+------+----------+-----------+----------+-------+------+
